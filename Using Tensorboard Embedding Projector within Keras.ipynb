{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 모델로 Tensorboard Embedding Projector 사용하기\n",
    "안녕하세요, 조교 정선우입니다! :)\n",
    "\n",
    "이번에 제가 Keras를 사용할 때, Tensorboard를 사용해서 Embedding을 비교적 쉽고 빠르게 시각화시키는 방법을 소개해 보려고 합니다.\n",
    "\n",
    "아래부터는 텐서보드에 대한 정보를 더 확인해보실 수 있는 URL과 예시 코드를 준비해 봤습니다.\n",
    "\n",
    "![](./nbsrc/imgs/teproj_0.PNG)\n",
    "\n",
    "\n",
    "### Tensorboard 관련 리소스\n",
    "아래 목록은 텐서보드로 Embedding Projection을 할 때 참고하기 좋은 리소스들입니다.\n",
    "\n",
    "- Keras Tensorboard 클래스 API 도큐먼트: https://keras.io/callbacks#tensorboard\n",
    "- Keras로 MNIST Embedding을 텐서보드에서 사용하는 예시: https://keras.io/examples/tensorboard_embeddings_mnist/\n",
    "\n",
    "\n",
    "- 텐서보드 Overview: https://www.tensorflow.org/tensorboard/r1/overview\n",
    "- 텐서보드 기본: https://www.tensorflow.org/tensorboard/r2/get_started\n",
    "- 텐서보드 Embedding: https://www.tensorflow.org/guide/embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예시\n",
    "이번 문서에서 예시로 할 Task는 Imagenet Weight를 가진 VGG16 모델에서 물고기와 새 이미지 12개의 Feature를 추출해 3D Space에 Embedding을 시키는 것입니다.\n",
    "\n",
    "코드 블럭마다 코드를 설명하는 주석이 달려 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 이번 예시에서 필요한 라이브러리를 Import 시켜줍니다.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random, os\n",
    "\n",
    "import keras as K\n",
    "from keras import Model\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from tk_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "윗 Cell에서 마지막으로 Import한 tk_helpers는 제가 직접 간단하게 만든 몇가지 편의용 유틸리티 함수를 담고 있습니다.\n",
    "\n",
    "- get_extension(파일경로): 주어진 파일 Path에서 파일의 확장자를 반환합니다.\n",
    "- load_image(파일경로): 주어진 이미지 파일 Path에서 PIL 이미지를 반환합니다.\n",
    "- load_images(디렉토리경로, 확장자 리스트): 주어진 디렉토리 경로에서 확장자 리스트 내 확장자를 가진 이미지 파일을 모두 가져옵니다.\n",
    "- resize_image(이미지, 사이즈): 주어진 PIL 이미지를 원하는 사이즈로 변형시킵니다.\n",
    "- center_crop_image(이미지, 사이즈): 주어진 PIL 이미지의 중앙으로부터 원하는 사이즈만큼 잘라서 반환합니다.\n",
    "\n",
    "각 함수는 아래 코드에서 사용하고 있으니 예시가 필요하다면 참고해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding시킬 데이터의 경로와 Tensorboard를 사용할 때 필요한 Log를 저장할 경로를 선언해줍니다\n",
    "FISH_IMG_DIR, BIRD_IMG_DIR = './data/fishes', './data/birds'\n",
    "LOG_DIR = './logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Trained VGG16 모델을 불러옵니다.\n",
    "m_vgg16 = VGG16(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/modudlc_ta/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"fc...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# VGG16에서 마지막 Classification 레이어를 사용하지 않고, 두번째 Dense 레이어를 Output으로 지정해줍니다.\n",
    "m_vgg16 = Model(input=m_vgg16.input, output=m_vgg16.get_layer('fc2').output)\n",
    "\n",
    "# Keras에서 Tensorboard를 사용하는 경우, 아직 모델에서 Fit 메서드를 부를 때에만 Embedding Projector를 사용할 수 있는 것으로 보입니다.\n",
    "# 때문에 모델을 학습시킬 때 필요한 파라미터를 지정해줍니다.\n",
    "m_vgg16.compile(\n",
    "    loss=K.losses.mean_squared_error,\n",
    "    optimizer=K.optimizers.Adam(lr=0.00001),\n",
    ")\n",
    "\n",
    "m_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 불러오기\n",
    "train_images = load_images(BIRD_IMG_DIR) + load_images(FISH_IMG_DIR)\n",
    "train_set = []\n",
    "\n",
    "# 불러온 이미지를 500x500 사이즈로 중앙에서 자른 뒤 224x224 사이즈로 줄여줍니다.\n",
    "for img in train_images:\n",
    "    train_set.append(np.array(resize_image(center_crop_img(img, (500, 500)), (224, 224))))\n",
    "\n",
    "# Train을 시킬 의도가 아니기 때문에 Fit에서 사용할 레이블은 랜덤으로 만들었습니다.\n",
    "# 더 나은 방법에 대한 아이디어가 있다면 언제든 말해주세요!\n",
    "train_set = np.array(train_set)\n",
    "label_set = np.random.rand(train_set.shape[0], 4096)\n",
    "\n",
    "# type_set 변수는 Embedding Projector에서 Metadata로 사용할 리스트 변수입니다.\n",
    "# 위에 train_set은 새 이미지 6개 이후 물고기 이미지 6개로 되어있기 때문에 각각 0과 1로 구분하였습니다.\n",
    "type_set = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata에 대해서\n",
    "윗 셀에서는 Tensorboard Embedding Projector에 사용할 Metadata를 저장했습니다. Metadata는 Embedding Projector를 사용할 때, 각각 Data Point에 레이블, 이미지와 같은 정보를 넣기 위해 사용됩니다.\n",
    "\n",
    "Metadata에 레이블을 넣는 경우, TSV 파일로 첫번째 줄은 헤더 정보를, 그 다음부터는 각 데이터 포인트의 정보를 담아서 저장해야 합니다. 예를 들어,\n",
    "\n",
    "<b> 헤더1\\t헤더2\n",
    "\n",
    "값1\\t값2 </b>\n",
    "\n",
    "이런 식으로 저장할 수 있는 것입니다.\n",
    "\n",
    "다음 링크에서 공식 웹사이트에 있는 정보를 확인할 수 있습니다. https://www.tensorflow.org/guide/embedding#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata를 저장해줍니다.\n",
    "with open(os.path.join(LOG_DIR, 'metadata.tsv'), 'w') as file:\n",
    "    file.write('Type\\tValue\\n')\n",
    "    for num in type_set:\n",
    "        file.write('{}\\t{}\\n'.format(num, random.randrange(0, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard 초기화 매개변수\n",
    "위에 텐서보드를 초기화시킬 때 지정한 각각의 파라미터에 대한 정보는 아래 사진에 설명되어 있습니다.\n",
    "\n",
    "\n",
    "![TB_ARG](./nbsrc/imgs/tb_arg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드 콜백 오브젝트를 만들어줍니다.\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir=LOG_DIR,\n",
    "    embeddings_freq=1,\n",
    "    embeddings_layer_names=['fc2'],\n",
    "    embeddings_metadata='metadata.tsv',\n",
    "    embeddings_data=train_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델에서 Fit을 실행하면서 callbacks 매개변수에 텐서보드 오브젝트를 넣어주면 모든 준비가 끝납니다.\n",
    "\n",
    "\n",
    "Fit을 하면 위에서 지정한 Log 디렉토리에 Tensorboard에서 사용할 체크포인트, Projector Config, Event까지 모두 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/modudlc_ta/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 30s 3s/step - loss: 2.5243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb59ee0d68>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_vgg16.fit(\n",
    "    train_set, label_set,\n",
    "    callbacks=[tensorboard],\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 커맨드를 사용하여 Tensorboard를 localhost:6006에 열어줍니다.\n",
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아직 해결하지 못한 문제\n",
    "1. Metadata에 Sprite를 사용해서 각 데이터포인트의 이미지 프리뷰를 만드는 방법은 아직 찾지 못했습니다.\n",
    "2. Fit (학습)을 사용하지 않고 Predict만을 사용해서 Embedding Projector를 사용하는 방법은 아직 찾지 못했습니다.\n",
    "\n",
    "이 문제들에 대해서 좋은 아이디어 있으시면 언제든지 말씀해주세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
